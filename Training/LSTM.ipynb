{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx0R5tY5AXqa"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install praat-parselmouth\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import parselmouth\n",
        "from tqdm import tqdm\n",
        "from functools import lru_cache\n",
        "\n",
        "# Path to TIMIT dataset\n",
        "timit_path = \"/content/drive/MyDrive/archive/data\"\n",
        "train_csv = \"/content/drive/MyDrive/train_phoneme_labels.csv\"\n",
        "test_csv = \"/content/drive/MyDrive/test_phoneme_labels.csv\"\n",
        "\n",
        "# Function to process a single .wav and .phn file\n",
        "def process_wav_phn(wav_path, phn_path):\n",
        "    phoneme_data = []\n",
        "\n",
        "    with open(phn_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            start_sample = int(parts[0])  # Start sample index\n",
        "            end_sample = int(parts[1])    # End sample index\n",
        "            phoneme = parts[2]            # Phoneme label\n",
        "            phoneme_data.append([wav_path, start_sample, end_sample, phoneme])\n",
        "\n",
        "    return phoneme_data\n",
        "\n",
        "# Separate lists for train and test\n",
        "train_data = []\n",
        "test_data = []\n",
        "\n",
        "# Walk through dataset and process files\n",
        "for root, _, files in os.walk(timit_path):\n",
        "    for file in files:\n",
        "        if file.endswith(\".WAV\"):\n",
        "            wav_path = os.path.join(root, file)\n",
        "            phn_path = wav_path.replace(\".WAV\", \".PHN\")\n",
        "\n",
        "            if os.path.exists(phn_path):  # Ensure .phn file exists\n",
        "                if \"TRAIN\" in root:\n",
        "                    train_data.extend(process_wav_phn(wav_path, phn_path))\n",
        "                elif \"TEST\" in root:\n",
        "                    test_data.extend(process_wav_phn(wav_path, phn_path))\n",
        "\n",
        "# Convert to DataFrames\n",
        "train_df = pd.DataFrame(train_data, columns=[\"WAV_File\", \"Start_Sample\", \"End_Sample\", \"Phoneme\"])\n",
        "test_df = pd.DataFrame(test_data, columns=[\"WAV_File\", \"Start_Sample\", \"End_Sample\", \"Phoneme\"])\n",
        "\n",
        "# Save to CSV\n",
        "train_df.to_csv(train_csv, index=False)\n",
        "test_df.to_csv(test_csv, index=False)\n",
        "\n",
        "print(f\"Saved TRAIN phoneme labels to {train_csv} ({len(train_df)} segments)\")\n",
        "print(f\"Saved TEST phoneme labels to {test_csv} ({len(test_df)} segments)\")\n",
        "\n",
        "def extract_audio_segment(wav_path, start_sample, end_sample, sr=16000, min_length=0.01):\n",
        "    try:\n",
        "        audio, _ = librosa.load(wav_path, sr=sr)\n",
        "        segment = audio[start_sample:end_sample]\n",
        "\n",
        "        # Check if segment is too short\n",
        "        if len(segment) < min_length * sr:\n",
        "            # Apply padding to minimum length\n",
        "            pad_size = int(min_length * sr) - len(segment)\n",
        "            segment = np.pad(segment, (0, pad_size), mode='constant')\n",
        "\n",
        "        return segment\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {wav_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def extract_praat_features(segment, sr=16000):\n",
        "    try:\n",
        "        # Save the audio to a temporary WAV file (Parselmouth expects file or array)\n",
        "        snd = parselmouth.Sound(segment, sampling_frequency=sr)\n",
        "\n",
        "        pitch = snd.to_pitch()\n",
        "        intensity = snd.to_intensity()\n",
        "        harmonicity = snd.to_harmonicity()\n",
        "        formants = snd.to_formant_burg()\n",
        "\n",
        "        features = []\n",
        "\n",
        "        # Pitch stats\n",
        "        pitch_values = pitch.selected_array['frequency']\n",
        "        pitch_values = pitch_values[pitch_values > 0]  # Remove unvoiced\n",
        "        features.append(np.mean(pitch_values) if len(pitch_values) > 0 else 0)\n",
        "        features.append(np.std(pitch_values) if len(pitch_values) > 0 else 0)\n",
        "\n",
        "        # Intensity\n",
        "        features.append(np.mean(intensity.values))\n",
        "        features.append(np.std(intensity.values))\n",
        "\n",
        "        # Harmonicity\n",
        "        harmonicity_values = harmonicity.values[0]\n",
        "        harmonicity_values = harmonicity_values[np.isfinite(harmonicity_values)]\n",
        "        features.append(np.mean(harmonicity_values) if len(harmonicity_values) > 0 else 0)\n",
        "\n",
        "        # Formants (mean F1 to F4)\n",
        "        for i in range(1, 5):\n",
        "            formant_values = []\n",
        "            for t in np.arange(0, snd.duration, 0.01):  # Every 10 ms\n",
        "                f = formants.get_value_at_time(i, t)\n",
        "                if f and not np.isnan(f) and f < 5000:\n",
        "                    formant_values.append(f)\n",
        "            features.append(np.mean(formant_values) if formant_values else 0)\n",
        "\n",
        "        return np.array(features)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Parselmouth error: {e}\")\n",
        "        return np.zeros(9)\n",
        "\n",
        "\n",
        "def extract_time_domain_features(segment, min_frames, n_features):\n",
        "    \"\"\"Comprehensive fallback feature extraction\"\"\"\n",
        "    if len(segment) == 0:\n",
        "        return np.zeros((min_frames, n_features))\n",
        "\n",
        "    # Basic time-domain features\n",
        "    features = [\n",
        "        np.max(np.abs(segment)),\n",
        "        np.mean(np.abs(segment)),\n",
        "        np.std(segment),\n",
        "        librosa.feature.zero_crossing_rate(\n",
        "            segment,\n",
        "            frame_length=len(segment),\n",
        "            center=False\n",
        "        )[0,0],\n",
        "        np.sum(segment**2),\n",
        "        *np.percentile(np.abs(segment), [10, 25, 50, 75, 90])\n",
        "    ]\n",
        "\n",
        "    # Spectral features from very short FFT\n",
        "    if len(segment) >= 8:\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "            spec = np.abs(librosa.stft(\n",
        "                segment,\n",
        "                n_fft=min(32, len(segment)),\n",
        "                center=False\n",
        "            ))\n",
        "            features.extend([\n",
        "                np.max(spec),\n",
        "                np.mean(spec),\n",
        "                np.median(spec)\n",
        "            ])\n",
        "\n",
        "    # Pad to required dimension\n",
        "    features = features[:n_features]\n",
        "    if len(features) < n_features:\n",
        "        features += [0.0] * (n_features - len(features))\n",
        "\n",
        "    return np.tile(features, (min_frames, 1))\n",
        "\n",
        "def process_dataset(df, sr=16000):\n",
        "    features = []\n",
        "    labels = []\n",
        "    problematic_files = []\n",
        "\n",
        "    # Using tqdm to show a progress bar during processing\n",
        "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing dataset\", unit=\"file\"):\n",
        "        wav_path = row['WAV_File']\n",
        "        start_sample = row['Start_Sample']  # Assuming these are sample indices\n",
        "        end_sample = row['End_Sample']\n",
        "        phoneme = row['Phoneme']\n",
        "\n",
        "        # Extract audio segment (using sample indices directly)\n",
        "        segment = extract_audio_segment(wav_path, start_sample, end_sample, sr=sr)\n",
        "\n",
        "        # Extract features\n",
        "        praat_features = extract_praat_features(segment, sr=sr)\n",
        "        features.append(praat_features)\n",
        "\n",
        "\n",
        "        # Store results\n",
        "        if mfcc_features is not None:\n",
        "            features.append(mfcc_features)\n",
        "            labels.append(phoneme)\n",
        "        else:\n",
        "            problematic_files.append(wav_path)\n",
        "\n",
        "    if problematic_files:\n",
        "        print(f\"Could not process {len(problematic_files)} files (e.g., {problematic_files[:3]}...)\")\n",
        "\n",
        "    # Stack features into 3D array: (n_samples, n_frames, n_mfcc)\n",
        "    features_array = np.stack(features)\n",
        "    labels_array = np.array(labels)\n",
        "\n",
        "    return features_array, labels_array\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/archive/data/train_phoneme_labels.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/archive/data/test_phoneme_labels.csv')\n",
        "\n",
        "# Process with checks\n",
        "print(\"Processing training data...\")\n",
        "train_features, train_labels = process_dataset(train_df)\n",
        "\n",
        "print(\"\\nProcessing test data...\")\n",
        "test_features, test_labels = process_dataset(test_df)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"\\nTrain features shape: {train_features.shape} (samples, frames, mfccs)\")\n",
        "print(f\"Test features shape: {test_features.shape}\")\n",
        "\n",
        "# 1. Prepare the data\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(train_labels)\n",
        "y_test_encoded = label_encoder.transform(test_labels)\n",
        "\n",
        "# Convert to one-hot\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y_train_onehot = to_categorical(y_train_encoded, num_classes=num_classes)\n",
        "y_test_onehot = to_categorical(y_test_encoded, num_classes=num_classes)\n",
        "\n",
        "# 2. Define the BLSTM model\n",
        "def create_blstm_model(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # BLSTM layers\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(inputs)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Bidirectional(LSTM(128))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Dense layers\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# 3. Create and compile the model\n",
        "input_shape = (train_features.shape[1],)  # e.g., (n_features,)  (frames, mfcc_features)\n",
        "model = create_blstm_model(input_shape, num_classes)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# 4. Train the model\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "# Optional: Create validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_features, y_train_onehot,\n",
        "    test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 5. Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(\n",
        "    test_features, y_test_onehot,\n",
        "    batch_size=batch_size,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# 6. Save the model\n",
        "model.save('phoneme_classification_blstm.h5')\n",
        "print(\"Model saved to phoneme_classification_blstm.h5\")"
      ]
    }
  ]
}